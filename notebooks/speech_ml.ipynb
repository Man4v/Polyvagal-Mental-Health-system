{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np\n",
    "\n",
    "def extract_features(file_path, max_pad_len=174):\n",
    "    try:\n",
    "        # sr = 22050\n",
    "        # desired_length = sr*4\n",
    "        audio, sample_rate = librosa.load(file_path, sr=None, res_type='kaiser_fast') \n",
    "        # librosa.util.fix_length(audio, size=desired_length)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        \n",
    "        # Pad or truncate\n",
    "        if mfccs.shape[1] < max_pad_len:\n",
    "            pad_width = max_pad_len - mfccs.shape[1]\n",
    "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mfccs = mfccs[:, :max_pad_len]\n",
    "            \n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e} | File: {file_path}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "emotion_map = {\n",
    "    \"01\": \"neutral\", \"02\": \"calm\", \"03\": \"happy\", \"04\": \"sad\",\n",
    "    \"05\": \"angry\", \"06\": \"fearful\", \"07\": \"disgust\", \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "files = glob.glob(\"../data/raw/kaggle_speech/**/*.wav\", recursive=True)\n",
    "files = [os.path.normpath(f) for f in files]  # normalize slashes\n",
    "\n",
    "for file in files:\n",
    "    file = os.path.normpath(file)\n",
    "    file_name = os.path.splitext(os.path.basename(file))[0]  # remove .wav\n",
    "    emotion = file_name.split(\"-\")[2]  # get emotion code\n",
    "    label = emotion_map[emotion]\n",
    "\n",
    "    feature = extract_features(file)\n",
    "    if feature is not None:\n",
    "        data.append(feature)\n",
    "        labels.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Label encoder saved as label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X = np.array(data)\n",
    "y = np.array(labels)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y = to_categorical(lb.fit_transform(y))\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(lb, \"../models/speech_label_encoder.pkl\")\n",
    "print(\"✅ Label encoder saved as label_encoder.pkl\")\n",
    "\n",
    "# Load later\n",
    "le_loaded = joblib.load(\"../models/speech_label_encoder.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# CNN expects 4D input\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "72/72 [==============================] - 11s 139ms/step - loss: 9.4839 - accuracy: 0.1398 - val_loss: 2.0786 - val_accuracy: 0.1337\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 10s 137ms/step - loss: 2.0836 - accuracy: 0.1276 - val_loss: 2.0734 - val_accuracy: 0.1458\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 10s 135ms/step - loss: 2.0441 - accuracy: 0.1680 - val_loss: 2.0305 - val_accuracy: 0.1771\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 1.9647 - accuracy: 0.2196 - val_loss: 2.0672 - val_accuracy: 0.2014\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 10s 133ms/step - loss: 1.9083 - accuracy: 0.2365 - val_loss: 1.9929 - val_accuracy: 0.2378\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 11s 152ms/step - loss: 1.8331 - accuracy: 0.2773 - val_loss: 1.8130 - val_accuracy: 0.2882\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 11s 159ms/step - loss: 1.7474 - accuracy: 0.3429 - val_loss: 1.6703 - val_accuracy: 0.3906\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 15s 210ms/step - loss: 1.5571 - accuracy: 0.4184 - val_loss: 1.3731 - val_accuracy: 0.5156\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 13s 176ms/step - loss: 1.4087 - accuracy: 0.4614 - val_loss: 1.2710 - val_accuracy: 0.5573\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 10s 143ms/step - loss: 1.1863 - accuracy: 0.5582 - val_loss: 1.1203 - val_accuracy: 0.6198\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 11s 153ms/step - loss: 1.0250 - accuracy: 0.6211 - val_loss: 0.9371 - val_accuracy: 0.6927\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 12s 166ms/step - loss: 0.8826 - accuracy: 0.6832 - val_loss: 0.7897 - val_accuracy: 0.7413\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 11s 157ms/step - loss: 0.7196 - accuracy: 0.7344 - val_loss: 0.7033 - val_accuracy: 0.7899\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 11s 156ms/step - loss: 0.5983 - accuracy: 0.7843 - val_loss: 0.6696 - val_accuracy: 0.7830\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 11s 156ms/step - loss: 0.5295 - accuracy: 0.8099 - val_loss: 0.5720 - val_accuracy: 0.8490\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 12s 164ms/step - loss: 0.4696 - accuracy: 0.8355 - val_loss: 0.5454 - val_accuracy: 0.8559\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 11s 157ms/step - loss: 0.4056 - accuracy: 0.8485 - val_loss: 0.4719 - val_accuracy: 0.8750\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 11s 158ms/step - loss: 0.3320 - accuracy: 0.8837 - val_loss: 0.5079 - val_accuracy: 0.8663\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 12s 161ms/step - loss: 0.3702 - accuracy: 0.8711 - val_loss: 0.4367 - val_accuracy: 0.8924\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 21s 287ms/step - loss: 0.2839 - accuracy: 0.8980 - val_loss: 0.4140 - val_accuracy: 0.8941\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 21s 293ms/step - loss: 0.2750 - accuracy: 0.8993 - val_loss: 0.4275 - val_accuracy: 0.8854\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 14s 196ms/step - loss: 0.2691 - accuracy: 0.9032 - val_loss: 0.4372 - val_accuracy: 0.8733\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 17s 231ms/step - loss: 0.2221 - accuracy: 0.9184 - val_loss: 0.4434 - val_accuracy: 0.8837\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 21s 289ms/step - loss: 0.2346 - accuracy: 0.9141 - val_loss: 0.3875 - val_accuracy: 0.8906\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 22s 300ms/step - loss: 0.1868 - accuracy: 0.9366 - val_loss: 0.4176 - val_accuracy: 0.8819\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 17s 238ms/step - loss: 0.1975 - accuracy: 0.9293 - val_loss: 0.4371 - val_accuracy: 0.8958\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 16s 224ms/step - loss: 0.1612 - accuracy: 0.9431 - val_loss: 0.4584 - val_accuracy: 0.8941\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 15s 207ms/step - loss: 0.1739 - accuracy: 0.9431 - val_loss: 0.4276 - val_accuracy: 0.8924\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 13s 181ms/step - loss: 0.1590 - accuracy: 0.9414 - val_loss: 0.4573 - val_accuracy: 0.8750\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 13s 181ms/step - loss: 0.1633 - accuracy: 0.9358 - val_loss: 0.4612 - val_accuracy: 0.8854\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 10s 132ms/step - loss: 0.1508 - accuracy: 0.9484 - val_loss: 0.4798 - val_accuracy: 0.8854\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 10s 140ms/step - loss: 0.1339 - accuracy: 0.9583 - val_loss: 0.5820 - val_accuracy: 0.8854\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 13s 182ms/step - loss: 0.1586 - accuracy: 0.9388 - val_loss: 0.5374 - val_accuracy: 0.8819\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 10s 139ms/step - loss: 0.1156 - accuracy: 0.9583 - val_loss: 0.4478 - val_accuracy: 0.8819\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 10s 142ms/step - loss: 0.1074 - accuracy: 0.9614 - val_loss: 0.4664 - val_accuracy: 0.8715\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 11s 153ms/step - loss: 0.1278 - accuracy: 0.9549 - val_loss: 0.5369 - val_accuracy: 0.8785\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 12s 164ms/step - loss: 0.1277 - accuracy: 0.9570 - val_loss: 0.5276 - val_accuracy: 0.8889\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 11s 157ms/step - loss: 0.1191 - accuracy: 0.9609 - val_loss: 0.6196 - val_accuracy: 0.8819\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 13s 187ms/step - loss: 0.1263 - accuracy: 0.9553 - val_loss: 0.4617 - val_accuracy: 0.8819\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 13s 177ms/step - loss: 0.1076 - accuracy: 0.9653 - val_loss: 0.4768 - val_accuracy: 0.8993\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 13s 185ms/step - loss: 0.1134 - accuracy: 0.9614 - val_loss: 0.6960 - val_accuracy: 0.8819\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 21s 295ms/step - loss: 0.1291 - accuracy: 0.9575 - val_loss: 0.4810 - val_accuracy: 0.8819\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 15s 206ms/step - loss: 0.1150 - accuracy: 0.9575 - val_loss: 0.5222 - val_accuracy: 0.8854\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 16s 228ms/step - loss: 0.1100 - accuracy: 0.9592 - val_loss: 0.6410 - val_accuracy: 0.8785\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 11s 158ms/step - loss: 0.1243 - accuracy: 0.9609 - val_loss: 0.4044 - val_accuracy: 0.8993\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 11s 159ms/step - loss: 0.1117 - accuracy: 0.9631 - val_loss: 0.5541 - val_accuracy: 0.8802\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 11s 157ms/step - loss: 0.1011 - accuracy: 0.9627 - val_loss: 0.4738 - val_accuracy: 0.8924\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 17s 235ms/step - loss: 0.0899 - accuracy: 0.9692 - val_loss: 0.5514 - val_accuracy: 0.8889\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 26s 356ms/step - loss: 0.0843 - accuracy: 0.9709 - val_loss: 0.5972 - val_accuracy: 0.8889\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 23s 321ms/step - loss: 0.0813 - accuracy: 0.9718 - val_loss: 0.6396 - val_accuracy: 0.8854\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(40, 174, 1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved as emotion_recognition_model.h5\n",
      "🔁 Reloaded model accuracy: 0.8854\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ==== SAVE MODEL ====\n",
    "# After training\n",
    "model.save(\"../models/speech_emotion_recognition_model.h5\")\n",
    "print(\"✅ Model saved as emotion_recognition_model.h5\")\n",
    "\n",
    "# ==== LOAD MODEL ====\n",
    "# In a new script / notebook later\n",
    "loaded_model = load_model(\"../models/speech_emotion_recognition_model.h5\")\n",
    "\n",
    "# Check if it loads correctly\n",
    "loss, acc = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"🔁 Reloaded model accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
