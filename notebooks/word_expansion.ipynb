{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (78.0.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manav\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manav\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypo words: ['numb', 'frozen', 'empty', 'heavy', 'alone', 'lonely', 'disconnected', 'hopeless', 'despair', 'invisible', 'withdrawn', 'dissociated', 'tired', 'faint', 'passive', 'foggy', 'apathetic', 'i can’t…', 'what’s the point?', 'low', 'weak', 'detached', 'spaced-out', 'slow', 'still', 'muted', 'distant', 'blank', 'vacant', 'shut down', 'fatigued', 'unmotivated', 'sluggish', 'dull', 'uninterested', 'silent', 'indifferent', 'lifeless', 'exhausted', 'unresponsive', 'powerless', 'isolated', 'lacking energy', 'collapsed', 'drained', 'flat', 'lack of will', 'checked out', \"can't move\", 'low-spirited', 'sad', 'unfeeling', 'quiet']\n",
      "Hyper words: ['anxious', 'angry', 'panicked', 'overwhelmed', 'restless', 'tight', 'racing', 'agitated', 'frustrated', 'tense', 'unsafe', 'defensive', 'rigid', 'chaotic', 'scattered', 'i have to…', 'i’m not safe', 'something bad will happen', 'uneasy', 'jumpy', 'short-tempered', 'over-alert', 'fidgety', 'hot', 'wound up', 'hyper', 'pressured', 'impatient', 'snappy', 'on edge', 'irritated', 'fearful', 'annoyed', 'overthinking', 'spinning', 'alarmed', 'suspicious', 'heart pounding', 'clenched', 'sweaty', 'out of control', 'rushing', 'breathing fast', 'keyed up', 'high-strung', 'hyperactive', 'jittery', 'aggressive', 'startled', 'urgent', \"can't relax\"]\n",
      "Flow words: ['safe', 'calm', 'open', 'engaged', 'curious', 'connected', 'clear', 'light', 'creative', 'playful', 'peaceful', 'present', 'trusting', 'grounded', 'relaxed', 'warm', 'i’m okay', 'i can handle this', 'i belong', 'confident', 'content', 'joyful', 'centered', 'steady', 'hopeful', 'loved', 'secure', 'bright', 'inspired', 'supportive', 'gentle', 'friendly', 'comfortable', 'patient', 'kind', 'compassionate', 'stable', 'adaptable', 'accepting', 'serene', 'focused', 'harmonious', 'grateful', 'cooperative', 'happy', 'rested', 'optimistic', 'easygoing', 'flexible', 'attentive', 'balanced', 'resilient', 'at ease']\n"
     ]
    }
   ],
   "source": [
    "json_path = \"../data/raw/initial_word_list.json\"\n",
    "\n",
    "# Load JSON\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    word_data = json.load(f)\n",
    "\n",
    "# Extract into lists\n",
    "hypo_words = word_data[\"hypo\"]\n",
    "hyper_words = word_data[\"hyper\"]\n",
    "flow_words = word_data[\"flow\"]\n",
    "\n",
    "print(\"Hypo words:\", hypo_words)\n",
    "print(\"Hyper words:\", hyper_words)\n",
    "print(\"Flow words:\", flow_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_words = {\n",
    "    \"hypo\": [\"numb\", \"disconnected\", \"hopeless\"],\n",
    "    \"hyper\": [\"anxious\", \"agitated\", \"unsafe\"],\n",
    "    \"flow\": [\"calm\", \"grounded\", \"safe\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     word state  weight\n",
      "0    numb  hypo    0.57\n",
      "1  frozen  hypo    0.37\n",
      "2   empty  hypo    0.39\n",
      "3   heavy  hypo    0.30\n",
      "4   alone  hypo    0.36\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to compute weight\n",
    "def get_weight(word, state, is_anchor=False):\n",
    "    if is_anchor:\n",
    "        return 1.0\n",
    "    \n",
    "    # Encode anchors & target word\n",
    "    anchors_vec = model.encode(anchor_words[state], convert_to_tensor=True)\n",
    "    word_vec = model.encode([word], convert_to_tensor=True)\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    sims = util.cos_sim(word_vec, anchors_vec)[0]\n",
    "    avg_sim = float(sims.mean())  # average similarity to all anchors\n",
    "    \n",
    "    # first scaling formula : to get weights in range 0.75 to 0.95 \n",
    "    # scaled_weight = 0.75 + (avg_sim * 0.20)\n",
    "    # Problem with scaling formula 1: not enough variation in weights\n",
    "\n",
    "    # second scaling formula : assign weight directly to the cosine similarity value\n",
    "    weight = max(0.3, avg_sim)\n",
    "    return round(weight, 2)\n",
    "\n",
    "# Build lexicon with weights\n",
    "lexicon = []\n",
    "for w in hypo_words:\n",
    "    lexicon.append({\"word\": w.lower(), \"state\": \"hypo\", \"weight\": get_weight(w, \"hypo\")})\n",
    "for w in hyper_words:\n",
    "    lexicon.append({\"word\": w.lower(), \"state\": \"hyper\", \"weight\": get_weight(w, \"hyper\")})\n",
    "for w in flow_words:\n",
    "    lexicon.append({\"word\": w.lower(), \"state\": \"flow\", \"weight\": get_weight(w, \"flow\")})\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(lexicon)\n",
    "df.to_csv(\"../data/processed/dataset_with_weights2.csv\", index=False)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
